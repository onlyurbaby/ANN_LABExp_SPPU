{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mjDFSTT-r68L"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    \"\"\"Sigmoid activation function\"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    \"\"\"Derivative of sigmoid function\"\"\"\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "lFAPktCKsIky"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(1)"
      ],
      "metadata": {
        "id": "F11PXSOssMVH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data (AND function)\n",
        "X = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]])\n",
        "\n",
        "y = np.array([[0], [0], [0], [1]])  # AND gate output"
      ],
      "metadata": {
        "id": "O8rMrxH2sQ4P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Network architecture\n",
        "input_neurons = 2\n",
        "hidden_neurons = 4  # Increased for better learning\n",
        "output_neurons = 1\n",
        "\n",
        "# Initialize weights with Xavier/Glorot initialization for better convergence\n",
        "w_input_hidden = np.random.randn(input_neurons, hidden_neurons) * np.sqrt(1/input_neurons)\n",
        "w_hidden_output = np.random.randn(hidden_neurons, output_neurons) * np.sqrt(1/hidden_neurons)\n",
        "\n",
        "# Initialize biases to small values\n",
        "b_hidden = np.zeros((1, hidden_neurons))\n",
        "b_output = np.zeros((1, output_neurons))"
      ],
      "metadata": {
        "id": "ZwA9sGabsTxY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "epochs = 10000  # Increased for better convergence\n",
        "learning_rate = 0.1\n",
        "print_interval = 1000  # Print loss less frequently\n",
        "\n",
        "# Arrays to store loss for plotting\n",
        "loss_history = []"
      ],
      "metadata": {
        "id": "8NzhUX6nsXS8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # --- Forward Propagation ---\n",
        "    hidden_input = np.dot(X, w_input_hidden) + b_hidden\n",
        "    hidden_output = sigmoid(hidden_input)\n",
        "\n",
        "    final_input = np.dot(hidden_output, w_hidden_output) + b_output\n",
        "    final_output = sigmoid(final_input)\n",
        "\n",
        "    # --- Calculate Loss ---\n",
        "    error = y - final_output\n",
        "    loss = np.mean(np.square(error))\n",
        "    loss_history.append(loss)\n",
        "\n",
        "    # --- Backpropagation ---\n",
        "    d_output = error * sigmoid_derivative(final_output)\n",
        "\n",
        "    error_hidden = d_output.dot(w_hidden_output.T)\n",
        "    d_hidden = error_hidden * sigmoid_derivative(hidden_output)\n",
        "\n",
        "    # --- Update Weights and Biases ---\n",
        "    w_hidden_output += hidden_output.T.dot(d_output) * learning_rate\n",
        "    b_output += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    w_input_hidden += X.T.dot(d_hidden) * learning_rate\n",
        "    b_hidden += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    # Print loss at intervals\n",
        "    if epoch % print_interval == 0:\n",
        "        print(f\"Epoch {epoch} Loss: {loss:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EidcliRLsagV",
        "outputId": "09166ffd-4d4d-4d44-87a7-75fa8f0ed4ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss: 0.239578\n",
            "Epoch 1000 Loss: 0.026046\n",
            "Epoch 2000 Loss: 0.007112\n",
            "Epoch 3000 Loss: 0.003503\n",
            "Epoch 4000 Loss: 0.002200\n",
            "Epoch 5000 Loss: 0.001563\n",
            "Epoch 6000 Loss: 0.001195\n",
            "Epoch 7000 Loss: 0.000959\n",
            "Epoch 8000 Loss: 0.000796\n",
            "Epoch 9000 Loss: 0.000678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the network\n",
        "print(\"\\nFinal predictions after training:\")\n",
        "print(final_output.round(4))\n",
        "\n",
        "# Expected outputs\n",
        "print(\"\\nExpected outputs:\")\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhOAt-VHsd9g",
        "outputId": "7d7cdef3-e1d9-4e96-aac2-6092df86641d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final predictions after training:\n",
            "[[2.00e-04]\n",
            " [2.49e-02]\n",
            " [2.25e-02]\n",
            " [9.65e-01]]\n",
            "\n",
            "Expected outputs:\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with new inputs\n",
        "def predict(input_data):\n",
        "    \"\"\"Make prediction with trained network\"\"\"\n",
        "    h_layer = sigmoid(np.dot(input_data, w_input_hidden) + b_hidden)\n",
        "    output = sigmoid(np.dot(h_layer, w_hidden_output) + b_output)\n",
        "    return output.round(4)"
      ],
      "metadata": {
        "id": "jgIkBA3BshAQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify each input individually\n",
        "print(\"\\nVerifying each input:\")\n",
        "for i in range(len(X)):\n",
        "    input_data = X[i:i+1]\n",
        "    prediction = predict(input_data)\n",
        "    print(f\"Input: {input_data[0]} → Output: {prediction[0][0]} (Expected: {y[i][0]})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6kJ43b7skDY",
        "outputId": "50ff6d33-8f6d-4d0f-d1db-c99945f8c5fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verifying each input:\n",
            "Input: [0 0] → Output: 0.0002 (Expected: 0)\n",
            "Input: [0 1] → Output: 0.0249 (Expected: 0)\n",
            "Input: [1 0] → Output: 0.0225 (Expected: 0)\n",
            "Input: [1 1] → Output: 0.965 (Expected: 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "64Q3J6YYsnt6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}